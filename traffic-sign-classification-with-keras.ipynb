{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Classification with Keras\n",
    "\n",
    "Keras exists to make coding deep neural networks simpler. To demonstrate just how easy it is, you’re going to use Keras to build a convolutional neural network in a few dozen lines of code.\n",
    "\n",
    "You’ll be connecting the concepts from the previous lessons to the methods that Keras provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The network you'll build with Keras is similar to the example that you can find in Keras’s GitHub repository that builds out a [convolutional neural network for MNIST](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py). \n",
    "\n",
    "However, instead of using the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, you're going to use the [German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) dataset that you've used previously.\n",
    "\n",
    "You can download pickle files with sanitized traffic sign data here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Here are the steps you'll take to build the network:\n",
    "\n",
    "1. First load the training data and do a train/validation split.\n",
    "2. Preprocess data.\n",
    "3. Build a feedforward neural network to classify traffic signs.\n",
    "4. Build a convolutional neural network to classify traffic signs.\n",
    "5. Evaluate performance of final neural network on testing data.\n",
    "\n",
    "Keep an eye on the network’s accuracy over time. Once the accuracy reaches the 98% range, you can be confident that you’ve built and trained an effective model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Start by importing the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Implement load the data here.\n",
    "with open('train.p', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Network\n",
    "Split the training data into a training and validation set.\n",
    "\n",
    "Measure the [validation accuracy](https://keras.io/models/sequential/) of the network after two training epochs.\n",
    "\n",
    "Hint: [Use the `train_test_split()` method](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY7CQJEnZGCwkSVI2/x+oJioRlMPfngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1273d3748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['labels'], bins = 43);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "X = data['features']\n",
    "y = data['labels']\n",
    "\n",
    "\n",
    "# TODO: Use `train_test_split` here.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, stratify = y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = np_utils.to_categorical(y_val, 43)\n",
    "y_train = np_utils.to_categorical(y_train, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STOP: Do not change the tests below. Your implementation should pass these tests. \n",
    "assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"\n",
    "assert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_val.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data\n",
    "\n",
    "Now that you've loaded the training data, preprocess the data such that it's in the range between -0.5 and 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Implement data normalization here.\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train = X_train / 255 - 0.5\n",
    "X_val = X_val / 255 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STOP: Do not change the tests below. Your implementation should pass these tests. \n",
    "assert(math.isclose(np.min(X_train), -0.5, abs_tol=1e-5) and math.isclose(np.max(X_train), 0.5, abs_tol=1e-5)), \"The range of the training data is: %.1f to %.1f\" % (np.min(X_train), np.max(X_train))\n",
    "assert(math.isclose(np.min(X_val), -0.5, abs_tol=1e-5) and math.isclose(np.max(X_val), 0.5, abs_tol=1e-5)), \"The range of the validation data is: %.1f to %.1f\" % (np.min(X_val), np.max(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Two-Layer Feedfoward Network\n",
    "\n",
    "The code you've written so far is for data processing, not specific to Keras. Here you're going to build Keras-specific code.\n",
    "\n",
    "Build a two-layer feedforward neural network, with 128 neurons in the fully-connected hidden layer. \n",
    "\n",
    "To get started, review the Keras documentation about [models](https://keras.io/models/sequential/) and [layers](https://keras.io/layers/core/).\n",
    "\n",
    "The Keras example of a [Multi-Layer Perceptron](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py) network is similar to what you need to do here. Use that as a guide, but keep in mind that there are a number of differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Build a two-layer feedforward neural network with Keras here.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop= EarlyStopping(min_delta= 0.008, patience= 1, verbose=1)\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(128, activation='relu', input_shape=(32*32*3,)))\n",
    "model1.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STOP: Do not change the tests below. Your implementation should pass these tests.\n",
    "dense_layers = []\n",
    "for l in model1.layers:\n",
    "    if type(l) == Dense:\n",
    "        dense_layers.append(l)\n",
    "assert(len(dense_layers) == 2), \"There should be 2 Dense layers.\"\n",
    "d1 = dense_layers[0]\n",
    "d2 = dense_layers[1]\n",
    "assert(d1.input_shape == (None, 3072))\n",
    "assert(d1.output_shape == (None, 128))\n",
    "assert(d2.input_shape == (None, 128))\n",
    "assert(d2.output_shape == (None, 43))\n",
    "\n",
    "last_layer = model1.layers[-1]\n",
    "assert(last_layer.activation.__name__ == 'softmax'), \"Last layer should be softmax activation, is {}.\".format(last_layer.activation.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1 (None, 3072) (None, 128) <function relu at 0x12295fd90>\n",
      "dense_2 (None, 128) (None, 43) <function softmax at 0x12295fb70>\n"
     ]
    }
   ],
   "source": [
    "# Debugging\n",
    "for l in model1.layers:\n",
    "    print(l.name, l.input_shape, l.output_shape, l.activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "Compile and train the network for 2 epochs. [Use the `adam` optimizer, with `categorical_crossentropy` loss.](https://keras.io/models/sequential/)\n",
    "\n",
    "Hint 1: In order to use categorical cross entropy, you will need to [one-hot encode the labels](https://github.com/fchollet/keras/blob/master/keras/utils/np_utils.py).\n",
    "\n",
    "Hint 2: In order to pass the input images to the fully-connected hidden layer, you will need to [reshape the input](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py).\n",
    "\n",
    "Hint 3: Keras's `.fit()` method returns a `History.history` object, which the tests below use. Save that to a variable named `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26270 samples, validate on 12939 samples\n",
      "Epoch 1/20\n",
      "26270/26270 [==============================] - 4s - loss: 1.9110 - acc: 0.5042 - val_loss: 1.1930 - val_acc: 0.6879\n",
      "Epoch 2/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.9514 - acc: 0.7496 - val_loss: 0.8151 - val_acc: 0.7639\n",
      "Epoch 3/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.6693 - acc: 0.8292 - val_loss: 0.7043 - val_acc: 0.7946\n",
      "Epoch 4/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.5281 - acc: 0.8667 - val_loss: 0.5379 - val_acc: 0.8601\n",
      "Epoch 5/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.4443 - acc: 0.8848 - val_loss: 0.4466 - val_acc: 0.8895\n",
      "Epoch 6/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.3734 - acc: 0.9052 - val_loss: 0.4177 - val_acc: 0.8947\n",
      "Epoch 7/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.3406 - acc: 0.9119 - val_loss: 0.4899 - val_acc: 0.8588\n",
      "Epoch 8/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.3126 - acc: 0.9181 - val_loss: 0.3270 - val_acc: 0.9120\n",
      "Epoch 9/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.2759 - acc: 0.9296 - val_loss: 0.3253 - val_acc: 0.9052\n",
      "Epoch 10/20\n",
      "26270/26270 [==============================] - 4s - loss: 0.2550 - acc: 0.9335 - val_loss: 0.3532 - val_acc: 0.8834\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compile and train the model here.\n",
    "\n",
    "X_train_flat = X_train.reshape(-1, 32*32*3)\n",
    "X_val_flat = X_val.reshape(-1, 32*32*3)\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history1 = model1.fit(X_train_flat, y_train,\n",
    "                    batch_size=128, nb_epoch=20,\n",
    "                    verbose=1, validation_data=(X_val_flat, y_val), callbacks = [earlystop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations\n",
    "You've built a feedforward neural network in Keras!\n",
    "\n",
    "Don't stop here! Next, you'll add a convolutional layer to drive.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "Build a new network, similar to your existing network. Before the hidden layer, add a 3x3 [convolutional layer](https://keras.io/layers/convolutional/#convolution2d) with 32 filters and valid padding.\n",
    "\n",
    "Then compile and train the network.\n",
    "\n",
    "Hint 1: The Keras example of a [convolutional neural network](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py) for MNIST would be a good example to review.\n",
    "\n",
    "Hint 2: Now that the first layer of the network is a convolutional layer, you no longer need to reshape the input images before passing them to the network. You might need to reload your training data to recover the original shape.\n",
    "\n",
    "Hint 3: Add a [`Flatten()` layer](https://keras.io/layers/core/#flatten) between the convolutional layer and the fully-connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Re-construct the network and add a convolutional layer before the first fully-connected layer.\n",
    "from keras.layers import Conv2D, Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_6 (Convolution2D)  (None, 30, 30, 32)    896         convolution2d_input_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 28800)         0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 128)           3686528     flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 43)            5547        dense_13[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 3692971\n",
      "____________________________________________________________________________________________________\n",
      "Train on 26270 samples, validate on 12939 samples\n",
      "Epoch 1/20\n",
      "26270/26270 [==============================] - 54s - loss: 1.2752 - acc: 0.6687 - val_loss: 0.5200 - val_acc: 0.8721\n",
      "Epoch 2/20\n",
      "26270/26270 [==============================] - 55s - loss: 0.3343 - acc: 0.9162 - val_loss: 0.2874 - val_acc: 0.9312\n",
      "Epoch 3/20\n",
      "26270/26270 [==============================] - 53s - loss: 0.1892 - acc: 0.9533 - val_loss: 0.2507 - val_acc: 0.9293\n",
      "Epoch 4/20\n",
      "26270/26270 [==============================] - 55s - loss: 0.1241 - acc: 0.9708 - val_loss: 0.1885 - val_acc: 0.9536\n",
      "Epoch 5/20\n",
      "26270/26270 [==============================] - 52s - loss: 0.0862 - acc: 0.9808 - val_loss: 0.1854 - val_acc: 0.9516\n",
      "Epoch 6/20\n",
      "26270/26270 [==============================] - 53s - loss: 0.0651 - acc: 0.9853 - val_loss: 0.1647 - val_acc: 0.9575\n",
      "Epoch 7/20\n",
      "26270/26270 [==============================] - 52s - loss: 0.0505 - acc: 0.9891 - val_loss: 0.1534 - val_acc: 0.9639\n",
      "Epoch 8/20\n",
      "26270/26270 [==============================] - 55s - loss: 0.0372 - acc: 0.9921 - val_loss: 0.1455 - val_acc: 0.9673\n",
      "Epoch 9/20\n",
      "26270/26270 [==============================] - 54s - loss: 0.0285 - acc: 0.9938 - val_loss: 0.1526 - val_acc: 0.9638\n",
      "Epoch 10/20\n",
      "26270/26270 [==============================] - 55s - loss: 0.0267 - acc: 0.9945 - val_loss: 0.1244 - val_acc: 0.9742\n",
      "Epoch 11/20\n",
      "26270/26270 [==============================] - 55s - loss: 0.0446 - acc: 0.9891 - val_loss: 0.1995 - val_acc: 0.9543\n",
      "Epoch 12/20\n",
      "26270/26270 [==============================] - 55s - loss: 0.0378 - acc: 0.9898 - val_loss: 0.1422 - val_acc: 0.9696\n",
      "Epoch 13/20\n",
      "26270/26270 [==============================] - 56s - loss: 0.0206 - acc: 0.9953 - val_loss: 0.1187 - val_acc: 0.9756\n",
      "Epoch 14/20\n",
      "26270/26270 [==============================] - 52s - loss: 0.0094 - acc: 0.9986 - val_loss: 0.1223 - val_acc: 0.9760\n",
      "Epoch 15/20\n",
      "26270/26270 [==============================] - 53s - loss: 0.0200 - acc: 0.9953 - val_loss: 0.1615 - val_acc: 0.9657\n",
      "Epoch 16/20\n",
      "26270/26270 [==============================] - 50s - loss: 0.0357 - acc: 0.9914 - val_loss: 0.2802 - val_acc: 0.9454\n",
      "Epoch 17/20\n",
      "26270/26270 [==============================] - 57s - loss: 0.0271 - acc: 0.9933 - val_loss: 0.1707 - val_acc: 0.9667\n",
      "Epoch 18/20\n",
      "26270/26270 [==============================] - 56s - loss: 0.0151 - acc: 0.9960 - val_loss: 0.1366 - val_acc: 0.9734\n",
      "Epoch 19/20\n",
      "26270/26270 [==============================] - 51s - loss: 0.0105 - acc: 0.9976 - val_loss: 0.1415 - val_acc: 0.9727\n",
      "Epoch 20/20\n",
      "26270/26270 [==============================] - 52s - loss: 0.0215 - acc: 0.9952 - val_loss: 0.1917 - val_acc: 0.9633\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3), activation='relu'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(43, activation='softmax'))\n",
    "\n",
    "model2.summary()\n",
    "# TODO: Compile and train the model here.\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train, y_train,\n",
    "                    batch_size=128, nb_epoch=20,\n",
    "                    verbose=1, validation_data=(X_val, y_val), callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "Re-construct your network and add a 2x2 [pooling layer](https://keras.io/layers/pooling/#maxpooling2d) immediately following your convolutional layer.\n",
    "\n",
    "Then compile and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Re-construct the network and add a pooling layer after the convolutional layer.\n",
    "# TODO: Re-construct the network and add a pooling layer after the convolutional layer.\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_3 (Convolution2D)  (None, 30, 30, 32)    896         convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 15, 15, 32)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 15, 15, 32)    0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 7200)          0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 128)           921728      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 43)            5547        dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 928171\n",
      "____________________________________________________________________________________________________\n",
      "Train on 26270 samples, validate on 12939 samples\n",
      "Epoch 1/20\n",
      "26270/26270 [==============================] - 35s - loss: 1.6869 - acc: 0.5554 - val_loss: 0.7810 - val_acc: 0.7858\n",
      "Epoch 2/20\n",
      "26270/26270 [==============================] - 38s - loss: 0.5027 - acc: 0.8749 - val_loss: 0.3932 - val_acc: 0.8885\n",
      "Epoch 3/20\n",
      "26270/26270 [==============================] - 35s - loss: 0.2624 - acc: 0.9395 - val_loss: 0.2329 - val_acc: 0.9430\n",
      "Epoch 4/20\n",
      "26270/26270 [==============================] - 32s - loss: 0.1677 - acc: 0.9631 - val_loss: 0.1692 - val_acc: 0.9616\n",
      "Epoch 5/20\n",
      "26270/26270 [==============================] - 34s - loss: 0.1168 - acc: 0.9774 - val_loss: 0.1568 - val_acc: 0.9597\n",
      "Epoch 6/20\n",
      "26270/26270 [==============================] - 36s - loss: 0.0885 - acc: 0.9824 - val_loss: 0.1118 - val_acc: 0.9744\n",
      "Epoch 7/20\n",
      "26270/26270 [==============================] - 38s - loss: 0.0664 - acc: 0.9887 - val_loss: 0.0991 - val_acc: 0.9785\n",
      "Epoch 8/20\n",
      "26270/26270 [==============================] - 33s - loss: 0.0721 - acc: 0.9837 - val_loss: 0.0952 - val_acc: 0.9757\n",
      "Epoch 9/20\n",
      "26270/26270 [==============================] - 33s - loss: 0.0436 - acc: 0.9919 - val_loss: 0.0851 - val_acc: 0.9796\n",
      "Epoch 10/20\n",
      "26270/26270 [==============================] - 40s - loss: 0.0324 - acc: 0.9945 - val_loss: 0.0723 - val_acc: 0.9841\n",
      "Epoch 11/20\n",
      "26270/26270 [==============================] - 40s - loss: 0.0269 - acc: 0.9959 - val_loss: 0.0839 - val_acc: 0.9812\n",
      "Epoch 12/20\n",
      "26270/26270 [==============================] - 33s - loss: 0.0246 - acc: 0.9960 - val_loss: 0.0898 - val_acc: 0.9800\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model3.add(MaxPooling2D((2,2)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dense(43, activation='softmax'))\n",
    "\n",
    "model3.summary()\n",
    "# TODO: Compile and train the model here.\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train, y_train,\n",
    "                    batch_size=128, nb_epoch=20,\n",
    "                    verbose=1, validation_data=(X_val, y_val), callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Re-construct your network and add [dropout](https://keras.io/layers/core/#dropout) after the pooling layer. Set the dropout rate to 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Re-construct the network and add dropout after the pooling layer.\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_4 (Convolution2D)  (None, 30, 30, 32)    896         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 15, 15, 32)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 15, 15, 32)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 15, 15, 32)    0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 7200)          0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 128)           921728      flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 43)            5547        dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 928171\n",
      "____________________________________________________________________________________________________\n",
      "Train on 26270 samples, validate on 12939 samples\n",
      "Epoch 1/20\n",
      "26270/26270 [==============================] - 38s - loss: 1.6784 - acc: 0.5587 - val_loss: 0.7203 - val_acc: 0.8338\n",
      "Epoch 2/20\n",
      "26270/26270 [==============================] - 38s - loss: 0.5414 - acc: 0.8571 - val_loss: 0.3684 - val_acc: 0.9168\n",
      "Epoch 3/20\n",
      "26270/26270 [==============================] - 36s - loss: 0.3230 - acc: 0.9183 - val_loss: 0.2353 - val_acc: 0.9455\n",
      "Epoch 4/20\n",
      "26270/26270 [==============================] - 37s - loss: 0.2341 - acc: 0.9396 - val_loss: 0.1806 - val_acc: 0.9605\n",
      "Epoch 5/20\n",
      "26270/26270 [==============================] - 38s - loss: 0.1808 - acc: 0.9546 - val_loss: 0.1688 - val_acc: 0.9634\n",
      "Epoch 6/20\n",
      "26270/26270 [==============================] - 40s - loss: 0.1513 - acc: 0.9614 - val_loss: 0.1269 - val_acc: 0.9704\n",
      "Epoch 7/20\n",
      "26270/26270 [==============================] - 42s - loss: 0.1321 - acc: 0.9655 - val_loss: 0.1146 - val_acc: 0.9719\n",
      "Epoch 8/20\n",
      "26270/26270 [==============================] - 39s - loss: 0.1124 - acc: 0.9701 - val_loss: 0.1018 - val_acc: 0.9761\n",
      "Epoch 9/20\n",
      "26270/26270 [==============================] - 40s - loss: 0.1035 - acc: 0.9724 - val_loss: 0.0904 - val_acc: 0.9758\n",
      "Epoch 10/20\n",
      "26270/26270 [==============================] - 40s - loss: 0.0899 - acc: 0.9758 - val_loss: 0.0809 - val_acc: 0.9825\n",
      "Epoch 11/20\n",
      "26270/26270 [==============================] - 38s - loss: 0.0783 - acc: 0.9788 - val_loss: 0.0862 - val_acc: 0.9796\n",
      "Epoch 12/20\n",
      "26270/26270 [==============================] - 41s - loss: 0.0782 - acc: 0.9802 - val_loss: 0.0828 - val_acc: 0.9773\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model4.add(MaxPooling2D((2,2)))\n",
    "model4.add((Dropout(0.5)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dense(43, activation='softmax'))\n",
    "\n",
    "model4.summary()\n",
    "# TODO: Compile and train the model here.\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history4 = model4.fit(X_train, y_train,\n",
    "                    batch_size=128, nb_epoch=20,\n",
    "                    verbose=1, validation_data=(X_val, y_val), callbacks = [earlystop])\n",
    "# TODO: Compile and train the model here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Validation Accuracy**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Congratulations! You've built a neural network with convolutions, pooling, dropout, and fully-connected layers, all in just a few lines of code.\n",
    "\n",
    "Have fun with the model and see how well you can do! Add more layers, or regularization, or different padding, or batches, or more training epochs.\n",
    "\n",
    "What is the best validation accuracy you can achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.55866006853283701,\n",
       "  0.85709935288307648,\n",
       "  0.91834792535841392,\n",
       "  0.93962695086279158,\n",
       "  0.95458698131577979,\n",
       "  0.96140083746171334,\n",
       "  0.96547392459708925,\n",
       "  0.97007993906225864,\n",
       "  0.97236391320898363,\n",
       "  0.97578987438142373,\n",
       "  0.97883517317414326,\n",
       "  0.98024362387383079],\n",
       " 'loss': [1.6783720971333649,\n",
       "  0.54136567103077715,\n",
       "  0.32304962565565815,\n",
       "  0.23411430820885112,\n",
       "  0.1808397036033027,\n",
       "  0.15133527495423604,\n",
       "  0.13206270812444465,\n",
       "  0.11241172612405431,\n",
       "  0.10347644052123293,\n",
       "  0.089924028176895154,\n",
       "  0.078296346365157574,\n",
       "  0.078172177112075275],\n",
       " 'val_acc': [0.83383569054334916,\n",
       "  0.9168405595486514,\n",
       "  0.94551356366782779,\n",
       "  0.96050699435814202,\n",
       "  0.96344385192055026,\n",
       "  0.97039956719993814,\n",
       "  0.97186799598114226,\n",
       "  0.97611871087410151,\n",
       "  0.97580956797279539,\n",
       "  0.98245614035087714,\n",
       "  0.97959656851379551,\n",
       "  0.97727799675399951],\n",
       " 'val_loss': [0.72025304358325593,\n",
       "  0.36842765778231745,\n",
       "  0.23528518776905041,\n",
       "  0.18059499518254393,\n",
       "  0.16880654595116854,\n",
       "  0.1268528216018287,\n",
       "  0.11460877867751397,\n",
       "  0.10180955636989841,\n",
       "  0.090417329681039188,\n",
       "  0.080942961924399662,\n",
       "  0.086153527200858296,\n",
       "  0.082849147018613525]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history4.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Validation Accuracy:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Once you've picked out your best model, it's time to test it.\n",
    "\n",
    "Load up the test data and use the [`evaluate()` method](https://keras.io/models/model/#evaluate) to see how well it does.\n",
    "\n",
    "Hint 1: The `evaluate()` method should return an array of numbers. Use the `metrics_names()` method to get the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Load test data\n",
    "with open('./test.p', mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "# TODO: Preprocess data & one-hot encode the labels\n",
    "X_test = test['features']\n",
    "y_test = test['labels']\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "X_test -= 0.5\n",
    "y_test = np_utils.to_categorical(y_test, 43)\n",
    "\n",
    "# TODO: Evaluate model on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.86440105602463746, 0.76247030874140564]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flat = X_test.reshape(-1, 32*32*3)\n",
    "model1.evaluate(X_test_flat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 10s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.79371107594771506, 0.88083927161336795]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 7s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.69315784700975847, 0.87537608863999705]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 8s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.55205653501897223, 0.88669833732991588]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Accuracy:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Keras is a great tool to use if you want to quickly build a neural network and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209,)\n"
     ]
    }
   ],
   "source": [
    "print (data['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12630,)\n"
     ]
    }
   ],
   "source": [
    "print (test['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY7CQJEnZGCwkSVI2/x+oJioRlMPfngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11422c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['labels'], bins =43);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1231f1f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test['labels'], bins = 43);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (type(data['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 32, 32, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print ((d[:1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:SDC]",
   "language": "python",
   "name": "conda-env-SDC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
